import json
import random
import os
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate

# ================= é…ç½® =================
OUTPUT_FILE = "experiment_dataset.json"
NUM_SAMPLES = 2  # ç”Ÿæˆå¤šå°‘ç»„æµ‹è¯•æ•°æ®
DISTRACTOR_MSG_COUNT = 10  # å¹²æ‰°æ¶ˆæ¯çš„æ¡æ•° (ç¡®ä¿è¶³å¤ŸæŠŠäº‹å®æŒ¤å‡ºçª—å£)
DISTRACTOR_MSG_LEN = 100   # æ¯æ¡å¹²æ‰°æ¶ˆæ¯å¤§æ¦‚å¤šå°‘å­—

# LLM åˆå§‹åŒ–
llm = ChatOpenAI(
    model="qwen-plus", 
    temperature=0.7,
    openai_api_key="sk-2770a3f619c14f31a87d47924de34af2", 
    openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

# è¯»å–èƒŒæ™¯æ–‡æœ¬
if not os.path.exists("background.txt"):
    # å¦‚æœæ²¡æœ‰æ–‡ä»¶ï¼Œç”Ÿæˆå‡æ•°æ®
    BACKGROUND_TEXT = "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºåˆ›é€ èƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æœºå™¨..." * 500
else:
    with open("background.txt", "r", encoding="utf-8") as f:
        BACKGROUND_TEXT = f.read()

def get_random_distractor_chunk(length):
    """ä»èƒŒæ™¯æ–‡æœ¬ä¸­éšæœºæˆªå–ä¸€æ®µ"""
    if len(BACKGROUND_TEXT) < length:
        return BACKGROUND_TEXT
    start = random.randint(0, len(BACKGROUND_TEXT) - length - 1)
    return BACKGROUND_TEXT[start : start + length].replace("\n", " ")

def generate_dataset():
    print(f"ğŸš€ æ­£åœ¨ç”Ÿæˆ {NUM_SAMPLES} ç»„å¤šè½®å¯¹è¯æµ‹è¯•æ•°æ®...")
    
    # å®šä¹‰ä¸‰ç§è®°å¿†ç±»å‹
    categories = ["å®ä½“ç»†èŠ‚ (Entity)", "å…³ç³»æ¨ç† (Relation)", "æ—¶åºæ•°å­— (Numeric)"]
    
    # Prompt: è®© LLM ç”Ÿæˆäº‹å®å’Œé—®é¢˜
    prompt = ChatPromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä¸ªæ•°æ®é›†ç”Ÿæˆä¸“å®¶ã€‚è¯·ç”Ÿæˆä¸€ç»„ç”¨äºæµ‹è¯• AI é•¿æœŸè®°å¿†çš„é—®ç­”æ•°æ®ã€‚
    
    æµ‹è¯•ç±»å‹: {category}
    
    è¦æ±‚ï¼š
    1. "fact": ä¸€ä¸ªç‹¬ç«‹çš„é™ˆè¿°å¥ï¼ŒåŒ…å«å…·ä½“çš„è™šæ„äº‹å®ï¼ˆä¸è¦ç”¨çœŸå®ä¸–ç•Œå¸¸è¯†ï¼‰ã€‚
    2. "question": é’ˆå¯¹è¯¥äº‹å®çš„æé—®ã€‚
    3. "answer": ç®€çŸ­çš„æ ‡å‡†ç­”æ¡ˆã€‚
    
    è¾“å‡º JSON æ ¼å¼:
    {{
        "fact": "...",
        "question": "...",
        "answer": "..."
    }}
    """)
    
    chain = prompt | llm | JsonOutputParser()
    dataset = []

    for i in range(NUM_SAMPLES):
        cat = random.choice(categories)
        try:
            # 1. ç”Ÿæˆæ ¸å¿ƒäº‹å®
            res = chain.invoke({"category": cat})
            
            # 2. ç”Ÿæˆå¤šæ¡å¹²æ‰°æ¶ˆæ¯ (æ¨¡æ‹Ÿå¤šè½®é—²èŠ)
            distractors = []
            for _ in range(DISTRACTOR_MSG_COUNT):
                # éšæœºæˆªå–ä¸€æ®µæ–‡æœ¬ï¼Œå¹¶åŠ ä¸Šä¸€ç‚¹å‰ç¼€è®©å®ƒçœ‹èµ·æ¥åƒå¯¹è¯
                chunk = get_random_distractor_chunk(DISTRACTOR_MSG_LEN)
                distractors.append(chunk)
                
            item = {
                "id": f"test_{i:03d}",
                "category": cat,
                "fact": res["fact"],
                "distractor_messages": distractors, # è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨
                "question": res["question"],
                "ground_truth": res["answer"]
            }
            dataset.append(item)
            print(f"  [{i+1}/{NUM_SAMPLES}] {cat}: {res['question']}")
            
        except Exception as e:
            print(f"  [Error] {e}")

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ•°æ®é›†å·²ä¿å­˜è‡³ {OUTPUT_FILE}")
    print(f"   ç»“æ„: 1æ¡äº‹å® -> {DISTRACTOR_MSG_COUNT}æ¡å¹²æ‰°å¯¹è¯ -> 1ä¸ªæé—®")

if __name__ == "__main__":
    generate_dataset()